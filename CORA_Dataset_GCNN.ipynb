{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf7ocJsKRvGZk7iORdoKkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adarsh-Vemali/Numerical_linear_algebra/blob/main/CORA_Dataset_GCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enu_mpfgsgf0",
        "outputId": "3c97abba-f617-4619-8ff4-499c84128ee3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m0.9/1.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "O62KftitlEJn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import GraphNorm\n",
        "from torch_geometric.datasets import Planetoid"
      ],
      "metadata": {
        "id": "LV0_ORDQlF1L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create saving directories if they do not exist\n",
        "if not os.path.exists(\"./training-runs\"):\n",
        "    os.mkdir(\"./training-runs\")\n",
        "\n",
        "if not os.path.exists(os.path.join(\"./training-runs\", \"gcn\")):\n",
        "    os.mkdir(os.path.join(\"./training-runs\", \"gcn\"))"
      ],
      "metadata": {
        "id": "kQGlelhIlMf4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create experiment directory for this run\n",
        "date = datetime.datetime.now().strftime('%Y-%m-%d-%H_%M_%S')\n",
        "SAVE_PATH = os.path.join(\"./training-runs\", \"gcn\", date)\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.mkdir(SAVE_PATH)"
      ],
      "metadata": {
        "id": "cD0-RvIjrtwP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cora = Planetoid(root=\"./\", name=\"Cora\", split=\"public\")\n",
        "cora_dataset = cora[0]\n",
        "cora_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOK4Z7Zgr8ER",
        "outputId": "590378bf-b0ef-408c-f157-caf52074fdb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print size of train, validation, and test set\n",
        "print(cora_dataset.train_mask.sum())\n",
        "print(cora_dataset.val_mask.sum())\n",
        "print(cora_dataset.test_mask.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPgURS2dr-K4",
        "outputId": "c0a90bba-0b97-471e-cc1c-16b7d6af48bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(140)\n",
            "tensor(500)\n",
            "tensor(1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"num_epochs\": 100,\n",
        "    \"hidden_size\": 40,\n",
        "    \"experiment description\": \"Two-hop GCN Network, hidden size 40, SGD optimizer + momentum=0.9, learning rate 1e-1. Dropout with probability 0.5 before GCN layers, Graph Norm after GCN layer.\"\n",
        "}"
      ],
      "metadata": {
        "id": "ec6gkfSJsAT4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_features, hidden_size, num_classes, training=True):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(input_features, hidden_size)\n",
        "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
        "\n",
        "        self.drop1 = nn.Dropout(p=0.5)\n",
        "        self.drop2 = nn.Dropout(p=0.5)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.norm1 = GraphNorm(hidden_size)\n",
        "        self.norm2 = GraphNorm(hidden_size)\n",
        "\n",
        "        self.lin1 = nn.Linear(in_features=hidden_size, out_features=num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.drop1(x)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.norm1(x)\n",
        "        x = self.act1(x)\n",
        "\n",
        "        x = self.drop2(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.norm2(x)\n",
        "        x = self.act2(x)\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "4X9f7mQusCIo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN(cora_dataset.num_node_features, hidden_size=args[\"hidden_size\"], num_classes=cora.num_classes).to(device)\n",
        "\n",
        "cora_dataset = cora_dataset.to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=args[\"learning_rate\"], weight_decay=5e-4)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=args[\"learning_rate\"], momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "BqbXBQh6sFI8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO1r82RdsHsW",
        "outputId": "ebf3783b-49fd-4f74-ca0a-3af95d2a99a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 40)\n",
            "  (conv2): GCNConv(40, 40)\n",
            "  (drop1): Dropout(p=0.5, inplace=False)\n",
            "  (drop2): Dropout(p=0.5, inplace=False)\n",
            "  (act1): ReLU()\n",
            "  (act2): ReLU()\n",
            "  (norm1): GraphNorm(40)\n",
            "  (norm2): GraphNorm(40)\n",
            "  (lin1): Linear(in_features=40, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(train_losses, val_losses):\n",
        "    assert len(train_losses) == len(val_losses), \"Inconsistent plotting sizes.\"\n",
        "\n",
        "    time = list(range(args[\"num_epochs\"]))\n",
        "    visual_df = pd.DataFrame({\n",
        "        \"Train Loss\": train_losses,\n",
        "        \"Validation Loss\": val_losses,\n",
        "        \"Epoch\": time\n",
        "    })\n",
        "\n",
        "    sns.lineplot(x='Epoch', y='Loss Value', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Loss Value\", var_name=\"Dataset Split\"))\n",
        "    plt.title(\"Loss Curves\")\n",
        "    plt.savefig(os.path.join(SAVE_PATH, \"loss_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
        "    plt.clf()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "BmrhWZOPsJq-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy_curves(train_acc, val_acc):\n",
        "    assert len(train_acc) == len(val_acc), \"Inconsistent plotting sizes.\"\n",
        "\n",
        "    time = list(range(args[\"num_epochs\"]))\n",
        "    visual_df = pd.DataFrame({\n",
        "        \"Train Accuracy\": train_acc,\n",
        "        \"Validation Accuracy\": val_acc,\n",
        "        \"Epoch\": time\n",
        "    })\n",
        "\n",
        "    sns.lineplot(x='Epoch', y='Accuracy', hue='Dataset Split', data=pd.melt(visual_df, ['Epoch'], value_name=\"Accuracy\", var_name=\"Dataset Split\"))\n",
        "    plt.title(\"Accuracy Curves\")\n",
        "    plt.savefig(os.path.join(SAVE_PATH, \"accuracy_curves.png\"), bbox_inches='tight', facecolor=\"white\")\n",
        "    plt.clf()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "gei9IneSsL9w"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, cora_dataset):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(args[\"num_epochs\"]):\n",
        "        if epoch % 20 == 0:\n",
        "            print(\"Epoch {} starting...\".format(epoch))\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(cora_dataset)  # Pass entire graph through model at once - batch gradient descent\n",
        "        loss = F.nll_loss(out[cora_dataset.train_mask], cora_dataset.y[cora_dataset.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct = (pred[cora_dataset.train_mask] == cora_dataset.y[cora_dataset.train_mask]).sum()\n",
        "        train_acc = int(correct) / int(cora_dataset.train_mask.sum())\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validate once per epoch\n",
        "        val_loss, val_acc = validation(model, cora_dataset)\n",
        "        val_losses.append(val_loss.item())\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "    # Assert that sizes are all the same\n",
        "    assert len(train_losses) == len(val_losses) == len(train_accuracies) == len(val_accuracies), \"Metric list sizes are inconsistent.\"\n",
        "    plot_loss_curves(train_losses, val_losses)\n",
        "    plot_accuracy_curves(train_accuracies, val_accuracies)"
      ],
      "metadata": {
        "id": "bZZ01oo2sOVD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, cora_dataset):\n",
        "    model.eval()\n",
        "    out = model(cora_dataset)\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    val_loss = F.nll_loss(out[cora_dataset.val_mask], cora_dataset.y[cora_dataset.val_mask])\n",
        "    correct = (pred[cora_dataset.val_mask] == cora_dataset.y[cora_dataset.val_mask]).sum()\n",
        "    val_acc = int(correct) / int(cora_dataset.val_mask.sum())\n",
        "\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "2NwXQ4yKsRF-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, cora_dataset):\n",
        "    model.eval()\n",
        "    pred = model(cora_dataset).argmax(dim=1)\n",
        "    correct = (pred[cora_dataset.test_mask] == cora_dataset.y[cora_dataset.test_mask]).sum()\n",
        "    accuracy = int(correct) / int(cora_dataset.test_mask.sum())\n",
        "    print(f'Test Set Accuracy: {accuracy:.4f}')\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "fmy9EU9OsTLC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, cora_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1SjSNBOsVKq",
        "outputId": "844f8d82-f923-4967-ac9b-ab1d1148b3d6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 starting...\n",
            "Epoch 20 starting...\n",
            "Epoch 40 starting...\n",
            "Epoch 60 starting...\n",
            "Epoch 80 starting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test(model, cora_dataset)\n",
        "\n",
        "# Save test accuracy so that we log it somewhere. Train and val accuracy are kept in the accuracy curves\n",
        "args[\"test accuracy\"] = test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdqiP0s6sXZ-",
        "outputId": "86c3ee71-44e6-4ba4-d124-63bfd5b5f7d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 0.7780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save training configuration and experiment description\n",
        "with open(os.path.join(SAVE_PATH, 'config.json'), 'w', encoding='utf-8') as f:\n",
        "    json.dump(args, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Print model definition\n",
        "open(os.path.join(SAVE_PATH, \"model_definition.txt\"), 'a').close()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA4sPE67sZ42",
        "outputId": "22bd7c51-22c1-4fbd-c1dc-9394001a19a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(1433, 40)\n",
            "  (conv2): GCNConv(40, 40)\n",
            "  (drop1): Dropout(p=0.5, inplace=False)\n",
            "  (drop2): Dropout(p=0.5, inplace=False)\n",
            "  (act1): ReLU()\n",
            "  (act2): ReLU()\n",
            "  (norm1): GraphNorm(40)\n",
            "  (norm2): GraphNorm(40)\n",
            "  (lin1): Linear(in_features=40, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2RGOac2sbzL"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}